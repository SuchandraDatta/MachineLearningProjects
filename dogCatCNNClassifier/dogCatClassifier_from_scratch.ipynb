{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dogCatClassifier_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSKbMAp0t5FB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680ba9c8-d6d7-4a95-a750-d823d008cc20"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import *\n",
        "from keras.layers import Dense, Dropout, Input, Flatten\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "model=Sequential();\n",
        "\n",
        "#One block\n",
        "model.add(Conv2D(64, (3,3), input_shape=(64,64,1), activation=\"relu\"));\n",
        "model.add(MaxPooling2D((3,3)))\n",
        "\n",
        "#Block two\n",
        "model.add(Conv2D(128, (3,3), activation=\"relu\"))\n",
        "model.add(Conv2D(256, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D((3,3)))\n",
        "\n",
        "#Block three\n",
        "model.add(Conv2D(256, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D((3,3)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#Final connections\n",
        "model.add(Dense(activation=\"relu\", units=256))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(activation=\"sigmoid\", units=1))\n",
        "\n",
        "model.compile(optimizer=\"adamax\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "print(model.summary());\n",
        "\n",
        "#Getting the data\n",
        "import pandas as pd\n",
        "dataset=pd.read_csv('/gdrive/My Drive/Colab Notebooks/dogCat/theFinalDataset.csv')\n",
        "image_array = []\n",
        "classLabels=[]\n",
        "\n",
        "for j in range(0, 10000):\n",
        " pyString=dataset.iloc[j].tolist()\n",
        " classLabels.append(np.array(pyString[0][-1]))\n",
        " for index, item in enumerate(pyString):\n",
        "        data = np.zeros((64,64), dtype=np.uint8)\n",
        "        pixel_data = item.split()\n",
        "        for i in range(0, 64):\n",
        "            pixel_index = i * 64\n",
        "            data[i] = pixel_data[pixel_index:pixel_index + 64]\n",
        "\n",
        "        normData=[x/255 for x in data]\n",
        "        image_array.append(np.array(normData))\n",
        "        \n",
        "        \n",
        "\n",
        "image_array = np.array(image_array)\n",
        "classLabels=np.asarray(classLabels)\n",
        "classLabels=[int(x) for x in classLabels]\n",
        "\n",
        "x_train, y_train, x_test, y_test = [], [], [], []\n",
        "x_train, x_test, y_train, y_test = train_test_split(image_array, classLabels, test_size=0.2, random_state=42)\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0],64,64,1)\n",
        "x_test=x_test.reshape(x_test.shape[0], 64,64,1)\n",
        "y_test = np.asarray(y_test)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "gen = ImageDataGenerator(featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "\n",
        "train_generator = gen.flow(x_train, y_train, batch_size=128)\n",
        "history=model.fit_generator(train_generator, steps_per_epoch=len(x_train)//128, epochs=70)\n",
        "\n",
        "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print('Train loss:', train_score[0])\n",
        "print('Train accuracy:', 100*train_score[1])\n",
        " \n",
        "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', test_score[0])\n",
        "print('Test accuracy:', 100*test_score[1])\n",
        "  \n",
        "model_json = model.to_json()\n",
        "with open(\"/gdrive/My Drive/Colab Notebooks/dogCat/model_archi_from_scratch.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/gdrive/My Drive/Colab Notebooks/dogCat/model_weights_from_scratch.h5\")\n",
        "print(\"Saved model to drive\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 62, 62, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 20, 20, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 18, 18, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 3, 3, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 1,025,793\n",
            "Trainable params: 1,025,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "62/62 [==============================] - 5s 66ms/step - loss: 0.6944 - accuracy: 0.5070\n",
            "Epoch 2/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.6767 - accuracy: 0.5855\n",
            "Epoch 3/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.6623 - accuracy: 0.6068\n",
            "Epoch 4/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.6502 - accuracy: 0.6263\n",
            "Epoch 5/70\n",
            "62/62 [==============================] - 4s 68ms/step - loss: 0.6406 - accuracy: 0.6296\n",
            "Epoch 6/70\n",
            "62/62 [==============================] - 4s 68ms/step - loss: 0.6264 - accuracy: 0.6433\n",
            "Epoch 7/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.6093 - accuracy: 0.6635\n",
            "Epoch 8/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.5927 - accuracy: 0.6807\n",
            "Epoch 9/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.5598 - accuracy: 0.7216\n",
            "Epoch 10/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.5428 - accuracy: 0.7331\n",
            "Epoch 11/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.5248 - accuracy: 0.7448\n",
            "Epoch 12/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.5115 - accuracy: 0.7492\n",
            "Epoch 13/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.5036 - accuracy: 0.7610\n",
            "Epoch 14/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.4749 - accuracy: 0.7721\n",
            "Epoch 15/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.4812 - accuracy: 0.7653\n",
            "Epoch 16/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.4746 - accuracy: 0.7762\n",
            "Epoch 17/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.4578 - accuracy: 0.7903\n",
            "Epoch 18/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.4483 - accuracy: 0.7889\n",
            "Epoch 19/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.4340 - accuracy: 0.8039\n",
            "Epoch 20/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.4442 - accuracy: 0.7912\n",
            "Epoch 21/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.4350 - accuracy: 0.8004\n",
            "Epoch 22/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.4211 - accuracy: 0.8067\n",
            "Epoch 23/70\n",
            "62/62 [==============================] - 4s 68ms/step - loss: 0.4101 - accuracy: 0.8144\n",
            "Epoch 24/70\n",
            "62/62 [==============================] - 4s 68ms/step - loss: 0.3942 - accuracy: 0.8188\n",
            "Epoch 25/70\n",
            "62/62 [==============================] - 4s 69ms/step - loss: 0.3915 - accuracy: 0.8277\n",
            "Epoch 26/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.3948 - accuracy: 0.8185\n",
            "Epoch 27/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.3817 - accuracy: 0.8247\n",
            "Epoch 28/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.3756 - accuracy: 0.8324\n",
            "Epoch 29/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.3742 - accuracy: 0.8421\n",
            "Epoch 30/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.3591 - accuracy: 0.8429\n",
            "Epoch 31/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.3588 - accuracy: 0.8372\n",
            "Epoch 32/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.3608 - accuracy: 0.8403\n",
            "Epoch 33/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.3630 - accuracy: 0.8467\n",
            "Epoch 34/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.3231 - accuracy: 0.8600\n",
            "Epoch 35/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.3369 - accuracy: 0.8513\n",
            "Epoch 36/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.3293 - accuracy: 0.8548\n",
            "Epoch 37/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.3096 - accuracy: 0.8651\n",
            "Epoch 38/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.3176 - accuracy: 0.8555\n",
            "Epoch 39/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.3101 - accuracy: 0.8666\n",
            "Epoch 40/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.2979 - accuracy: 0.8737\n",
            "Epoch 41/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.3074 - accuracy: 0.8651\n",
            "Epoch 42/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2969 - accuracy: 0.8734\n",
            "Epoch 43/70\n",
            "62/62 [==============================] - 4s 68ms/step - loss: 0.2917 - accuracy: 0.8734\n",
            "Epoch 44/70\n",
            "62/62 [==============================] - 4s 68ms/step - loss: 0.2839 - accuracy: 0.8733\n",
            "Epoch 45/70\n",
            "62/62 [==============================] - 4s 68ms/step - loss: 0.2895 - accuracy: 0.8819\n",
            "Epoch 46/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.2830 - accuracy: 0.8766\n",
            "Epoch 47/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2748 - accuracy: 0.8844\n",
            "Epoch 48/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2756 - accuracy: 0.8837\n",
            "Epoch 49/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2584 - accuracy: 0.8934\n",
            "Epoch 50/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2653 - accuracy: 0.8857\n",
            "Epoch 51/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2611 - accuracy: 0.8903\n",
            "Epoch 52/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.2417 - accuracy: 0.9006\n",
            "Epoch 53/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2388 - accuracy: 0.8999\n",
            "Epoch 54/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2372 - accuracy: 0.8967\n",
            "Epoch 55/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.2396 - accuracy: 0.9006\n",
            "Epoch 56/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2318 - accuracy: 0.9001\n",
            "Epoch 57/70\n",
            "62/62 [==============================] - 4s 65ms/step - loss: 0.2394 - accuracy: 0.9028\n",
            "Epoch 58/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2389 - accuracy: 0.8943\n",
            "Epoch 59/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2249 - accuracy: 0.9031\n",
            "Epoch 60/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2253 - accuracy: 0.9058\n",
            "Epoch 61/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2682 - accuracy: 0.8838\n",
            "Epoch 62/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2102 - accuracy: 0.9127\n",
            "Epoch 63/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.2257 - accuracy: 0.9061\n",
            "Epoch 64/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2014 - accuracy: 0.9153\n",
            "Epoch 65/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.1980 - accuracy: 0.9211\n",
            "Epoch 66/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2008 - accuracy: 0.9170\n",
            "Epoch 67/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2102 - accuracy: 0.9137\n",
            "Epoch 68/70\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 0.1949 - accuracy: 0.9188\n",
            "Epoch 69/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.2097 - accuracy: 0.9167\n",
            "Epoch 70/70\n",
            "62/62 [==============================] - 4s 66ms/step - loss: 0.1939 - accuracy: 0.9177\n",
            "Train loss: 0.18296410143375397\n",
            "Train accuracy: 92.25000143051147\n",
            "Test loss: 0.338436096906662\n",
            "Test accuracy: 86.2500011920929\n",
            "Saved model to drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}