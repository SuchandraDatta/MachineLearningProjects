{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vectorized_Logistic_Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItuazqZ3yor9",
        "outputId": "300b0ecd-c1a4-48f5-cc93-7fd8223d59da"
      },
      "source": [
        "#For calculations, X must be of shape(Number of features, Number of training samples) so given the dataset where the #observations are row-wise we take the transpose of it to get the observations column-wise. This helps in #vectorization and the bias must be taken as a separate term not part of the theta matrix\r\n",
        "from scipy.special import expit\r\n",
        "\r\n",
        "def predict(thetaParam,bias, x_params):\r\n",
        "    x_params=np.asarray(x_params)\r\n",
        "    x_params=x_params.T\r\n",
        "    print(\"x_params=\", x_params,\"\\ttheta=\", thetaParam)\r\n",
        "    ans=np.dot(thetaParam, x_params)+bias\r\n",
        "    print(\"ans=\", ans)\r\n",
        "    return ans\r\n",
        "  \r\n",
        "import numpy as np\r\n",
        "x=[\r\n",
        "   [2.7810836,\t2.550537003 ],\r\n",
        "   [1.465489372,\t2.362125076 ],\r\n",
        "   [ 3.396561688,\t4.400293529],\r\n",
        "   [ 1.38807019,\t1.850220317],\r\n",
        "   [3.06407232,\t3.005305973],\r\n",
        "   [ 7.627531214,\t2.759262235],\r\n",
        "   [5.332441248,\t2.088626775],\r\n",
        "   [ 6.922596716,\t1.77106367],\r\n",
        "   [8.675418651,\t-0.2420686549],\r\n",
        "   [ 7.673756466,\t3.508563011 ]\r\n",
        "   ]\r\n",
        "y=[0,0,0,0,0,1,1,1,1,1]\r\n",
        "\r\n",
        "x=np.asarray(x)\r\n",
        "y=np.asarray(y)\r\n",
        "print(\"X=\", x)\r\n",
        "print(\"Y=\", y)\r\n",
        "\r\n",
        "flag=0\r\n",
        "theta=np.random.rand(x.shape[1])\r\n",
        "theta=np.asarray(theta)\r\n",
        "bias=np.random.rand(1)\r\n",
        "lambda_term=0\r\n",
        "x=x.T\r\n",
        "m=x.shape[1]\r\n",
        "alpha=0.01\r\n",
        "while(True):\r\n",
        "    flag=0\r\n",
        "    #h(x)\r\n",
        "    step1=np.dot(theta,x)+bias\r\n",
        "    step1=expit(step1)#To apply sigmoid function to every term of step1\r\n",
        "    #ylog(h(x))-(1-y)log(1-h(x))\r\n",
        "    step2=0\r\n",
        "    step2=step2-y*np.log(step1)-(1-y)*np.log(1-step1)\r\n",
        "    #If the value of step1 or 1-step1 becomes zero(which it does after lots of iterations and nearer the minimum, log(0)=math error -inf so we break the loop)\r\n",
        "    if(np.isnan(np.sum(step2))):\r\n",
        "        break\r\n",
        "     \r\n",
        "    cost_function=np.sum(step2)\r\n",
        "    #print(\"Cost function part 1: \", cost_function)\r\n",
        "    cost_function=(cost_function)/(2*m)+lambda_term*(np.sum(np.square(theta)))/(2*m)\r\n",
        "    #print(\"Cost function with R2 regularization term: \", cost_function)\r\n",
        "\r\n",
        "    step3=np.dot(x, (step1-y))\r\n",
        "    #print(step3)\r\n",
        "    change_theta=theta*(1-(alpha*lambda_term)/m)-(alpha/m)*step3\r\n",
        "    change_bias=bias-(alpha/m)*np.sum((step1-y))\r\n",
        "    hold_array=np.abs(theta-change_theta)\r\n",
        "    if(hold_array.any()>=1e-05):\r\n",
        "        flag=1\r\n",
        "    #print(\"change_theta=\", change_theta)\r\n",
        "    #print(\"change_bias=\", change_bias)\r\n",
        "    if(flag==0):\r\n",
        "        print(\"Converged\")\r\n",
        "        break\r\n",
        "    theta=change_theta\r\n",
        "    bias=change_bias\r\n",
        "    \r\n",
        "print(\"THETA=\", theta)\r\n",
        "print(\"BIAS=\", bias)\r\n",
        "#The actual answer is THETA= [ 4.27105379 -6.5152645 ]\r\n",
        "#BIAS= [-1.89351873]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X= [[ 2.7810836   2.550537  ]\n",
            " [ 1.46548937  2.36212508]\n",
            " [ 3.39656169  4.40029353]\n",
            " [ 1.38807019  1.85022032]\n",
            " [ 3.06407232  3.00530597]\n",
            " [ 7.62753121  2.75926224]\n",
            " [ 5.33244125  2.08862677]\n",
            " [ 6.92259672  1.77106367]\n",
            " [ 8.67541865 -0.24206865]\n",
            " [ 7.67375647  3.50856301]]\n",
            "Y= [0 0 0 0 0 1 1 1 1 1]\n",
            "THETA= [ 4.29339353 -6.48216801]\n",
            "BIAS= [-2.07931238]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}